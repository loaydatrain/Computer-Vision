{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zo8fDiZYIE0k"
   },
   "source": [
    "# LOAY RASHID 2018102008\n",
    "\n",
    "List of things done:\n",
    "- Used pretrained resnet 50 with frozen layers, added 2 layers which were trained\n",
    "\n",
    "- Applied a few basic transforms to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VHQN9EFeJAEr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "82DFmOJZ5mF5"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0n8XZKR90UJg"
   },
   "outputs": [],
   "source": [
    "!wget -q https://datasets.aicrowd.com/default/aicrowd-practice-challenges/public/foodc/v0.1/train_images.zip\n",
    "!wget -q https://datasets.aicrowd.com/default/aicrowd-practice-challenges/public/foodc/v0.1/test_images.zip\n",
    "!wget -q https://datasets.aicrowd.com/default/aicrowd-practice-challenges/public/foodc/v0.1/train.csv\n",
    "!wget -q https://datasets.aicrowd.com/default/aicrowd-practice-challenges/public/foodc/v0.1/test.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z9XfPwVM2GoH"
   },
   "outputs": [],
   "source": [
    "!mkdir data\n",
    "!mkdir data/test\n",
    "!mkdir data/train\n",
    "!unzip train_images -d data/train\n",
    "!unzip test_images -d data/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BEEA7ixs5U91"
   },
   "outputs": [],
   "source": [
    "class FoodData(Dataset):\n",
    "    def __init__(self,data_list,data_dir = './',transform=None,train=True):\n",
    "        super().__init__()\n",
    "        self.data_list = data_list\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data_list.shape[0]\n",
    "    \n",
    "    def __getitem__(self,item):\n",
    "        if self.train:\n",
    "          img_name,label = self.data_list.iloc[item]\n",
    "        else:\n",
    "          img_name = self.data_list.iloc[item]['ImageId']\n",
    "        img_path = os.path.join(self.data_dir,img_name)\n",
    "        img = cv2.imread(img_path,1)\n",
    "        img = cv2.resize(img,(256,256))\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        if self.train:\n",
    "          return {\n",
    "              'gt' : img,\n",
    "              'label' : torch.tensor(label)\n",
    "\n",
    "          }\n",
    "        else:\n",
    "          return {\n",
    "              'gt':img\n",
    "          }        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XOo5Q96onPVW"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "le = preprocessing.LabelEncoder()\n",
    "targets = le.fit_transform(train['ClassName'])\n",
    "ntrain = train\n",
    "ntrain['ClassName'] = targets  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BBwgTv6v-JjC"
   },
   "outputs": [],
   "source": [
    "transforms_train = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomAffine(degrees=40, scale=(.9, 1.1), shear=0),\n",
    "    transforms.ColorJitter(brightness=0.4,contrast=0.4,saturation=0.4),\n",
    "    transforms.Normalize((0.3166, 0.3947, 0.4725), (0.1755, 0.1720, 0.1657))\n",
    "])\n",
    "train_path = 'data/train/train_images'\n",
    "train_data = FoodData(data_list= ntrain,data_dir = train_path,transform = transforms_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KQx0SjTzC8rD"
   },
   "outputs": [],
   "source": [
    "batch = 128\n",
    "valid_size = 0.2\n",
    "num = train_data.__len__()\n",
    "# Dividing the indices for train and cross validation\n",
    "indices = list(range(num))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(valid_size*num))\n",
    "train_idx,valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "#Create Samplers\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size = batch, sampler = train_sampler)\n",
    "valid_loader = DataLoader(train_data, batch_size = batch, sampler = valid_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ozAU2IdEDzCl"
   },
   "outputs": [],
   "source": [
    "transforms_test = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5) , (0.5,0.5,0.5))\n",
    "])\n",
    "test_path = 'data/test/test_images'\n",
    "test = pd.read_csv('test.csv')\n",
    "test_data = FoodData(data_list= test,data_dir = test_path,transform = transforms_test,train=False)\n",
    "\n",
    "test_loader = DataLoader(test_data, batch_size=batch, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l_W_9ZtdD1Mb",
    "outputId": "b5602474-fde8-4085-a81e-d2b9ea0e8541"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "92A9tjBo_Lpt"
   },
   "source": [
    "Here we define our model object along with our optimizer and error function. Typically for multi class classification we use `Cross Entropy Loss`. More about different types of losses are [here](https://pytorch.org/docs/stable/nn.html#loss-functions).   \n",
    "We use the popular Adam optimizer with its default parameters. There are other optimizers like `SGD`, `RMSPROP`, `Adamax`,etc. You can have a detailed look at optimizers [here](https://pytorch.org/docs/stable/optim.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5wgZsoAMEqpe"
   },
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "error = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pw0LWxz1F1NL"
   },
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True).to(device)\n",
    "    \n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False   \n",
    "    \n",
    "model.fc = nn.Sequential(\n",
    "               nn.Linear(2048, 128),\n",
    "               nn.ReLU(inplace=True),\n",
    "               nn.Linear(128, 61)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DP2tKVAuF2j7"
   },
   "outputs": [],
   "source": [
    "error = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.fc.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ocymwmaNGFfg",
    "outputId": "02c8c04e-cae1-47cc-9a0e-3812d7a526c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \tTraining Loss: 2.333293 \tValidation Loss: 2.218895\n",
      "Validation Loss decreased inf -> 2.218895\n",
      "Epoch: 1 \tTraining Loss: 2.049859 \tValidation Loss: 2.022505\n",
      "Validation Loss decreased 2.218895 -> 2.022505\n",
      "Epoch: 2 \tTraining Loss: 1.867413 \tValidation Loss: 1.887063\n",
      "Validation Loss decreased 2.022505 -> 1.887063\n",
      "Epoch: 3 \tTraining Loss: 1.778317 \tValidation Loss: 1.846909\n",
      "Validation Loss decreased 1.887063 -> 1.846909\n",
      "Epoch: 4 \tTraining Loss: 1.679658 \tValidation Loss: 1.780733\n",
      "Validation Loss decreased 1.846909 -> 1.780733\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "valid_loss_min = np.Inf\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    model.train()\n",
    "    for images in train_loader:\n",
    "        data = images['gt'].squeeze(0).to(device)\n",
    "        # data = data.squeeze(0)\n",
    "        target = images['label'].to(device)\n",
    "#             clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "#         forward pass the model\n",
    "        output = model(data)\n",
    "#     backward pass the model\n",
    "        loss = error(output,target)\n",
    "        loss.backward()\n",
    "#         Perform a single optimization step\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    model.eval()\n",
    "    for images in valid_loader:\n",
    "        data = images['gt'].squeeze(0).to(device)\n",
    "        target = images['label'].to(device)\n",
    "#         forward pass now\n",
    "        output = model(data)\n",
    "#         calculate the branch loss\n",
    "        loss = error(output, target)\n",
    "#     update average validation loss\n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "    \n",
    "    train_loss /= len(train_loader.sampler)\n",
    "    valid_loss /= len(valid_loader.sampler)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss))\n",
    "    \n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print(\"Validation Loss decreased {:0.6f} -> {:0.6f}\".format(valid_loss_min,valid_loss))\n",
    "        valid_loss_min = valid_loss\n",
    "        torch.save(model.state_dict(), 'best_model_so_far.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCppJXybBvqq"
   },
   "source": [
    "## Predict on Validation\n",
    "Now we predict our trained model on the validation set and evaluate our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aFau5IeyG3c3",
    "outputId": "32241741-8c75-495f-ddd4-ad95a9b6078d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 49.409871 %\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('best_model_so_far.pth'))\n",
    "model.eval() \n",
    "correct = 0\n",
    "total = 0\n",
    "pred_list = []\n",
    "correct_list = []\n",
    "with torch.no_grad():\n",
    "    for images in valid_loader:\n",
    "        data = images['gt'].squeeze(0).to(device)\n",
    "        target = images['label'].to(device)\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += target.size(0)\n",
    "        pr = predicted.detach().cpu().numpy()\n",
    "        for i in pr:\n",
    "          pred_list.append(i)\n",
    "        tg = target.detach().cpu().numpy()\n",
    "        for i in tg:\n",
    "          correct_list.append(i)\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AHhrW6WZkG1P"
   },
   "source": [
    "## Evaluate the Performance\n",
    "We use the same metrics as that will be used for the test set.  \n",
    "[F1 score](https://en.wikipedia.org/wiki/F1_score) and [Log Loss](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html) are the metrics for this challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "167pHkZTKshk",
    "outputId": "99ede4e1-1a37-4380-8ad5-9f10bf460c1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score : 0.49409871244635195\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score,precision_score,log_loss   \n",
    "print(\"F1 score :\",f1_score(correct_list,pred_list,average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BCP85OMQDE3C"
   },
   "source": [
    "## Predict on test set\n",
    "Time for the moment of truth! Predict on test set and time to make the submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qE19LWBnhowq"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best_model_so_far.pth'))\n",
    "model.eval()\n",
    "\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for images in test_loader:\n",
    "        data = images['gt'].squeeze(0).to(device)\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        pr = predicted.detach().cpu().numpy()\n",
    "        for i in pr:\n",
    "          preds.append(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9nCB-d-yDUEc"
   },
   "source": [
    "## Save it in correct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LGiuketcDOYg"
   },
   "outputs": [],
   "source": [
    "# Create Submission file        \n",
    "df = pd.DataFrame(le.inverse_transform(preds),columns=['ClassName'])\n",
    "df.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nW0Eh62ZDV94"
   },
   "source": [
    "## To download the generated in collab csv run the below command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "aL36neEfrvcO",
    "outputId": "81e20619-e7fb-48fd-dc27-575b1e32b817"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_1669b4a4-0618-4de8-a5a0-5f34b6f32c61\", \"submission.csv\", 5977)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.download('submission.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RM_Rkc5UDYjD"
   },
   "source": [
    "### Go to [platform](https://www.aicrowd.com/challenges/aicrowd-blitz-may-2020/problems/foodc). Participate in the challenge and submit the submission.csv."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "2033_asgn5_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
